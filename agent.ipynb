{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from dotenv import load_dotenv\n",
    "from langchain.agents import AgentExecutor\n",
    "from langchain.agents import create_tool_calling_agent\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "search = TavilySearchResults()\n",
    "# query = \"what is the weather in SF\"\n",
    "# search.invoke(query)\n",
    "tools = [search]\n",
    "\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "model = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\")\n",
    "agent = create_tool_calling_agent(model, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "agent_executor.invoke({\"input\": \"whats the weather in sf?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User:  Hey, how are you\n",
      "AI:  I am doing well, thank you for asking! How can I assist you today? ðŸ˜Š\n",
      "User:  Well i wanted to ask if you can tell me where the temperature is ?\n",
      "AI:  To tell you the temperature, I need to know your location. Could you please tell me where you are?\n",
      "User:  Well i am currently from jaipur\n",
      "AI:  It looks like Jaipur is experiencing sunny and warm weather right now. You can find more detailed weather information, including the current temperature, on websites like AccuWeather or Time and Date.\n",
      "User:  Can you tell me the temperature right now\n",
      "AI:  The current temperature in Jaipur is 26Â°C.\n",
      "User:  Okay from Jaipur to Chennai, what are the flight costs of economy flights?\n",
      "AI:  Based on current searches, the cheapest flight from Jaipur to Chennai is around â‚¹5415. However, prices vary depending on the date and airline. February is generally the cheapest month to fly.  I recommend checking flight comparison websites for the most up-to-date prices. ðŸ˜Š\n",
      "User:  I mean Jaipur to Japan\n",
      "AI:  Based on current searches, the cheapest flight from Jaipur to Japan is around â‚¹43,309. However, prices can vary depending on the date, airline, and availability. I recommend checking flight comparison websites like Skyscanner or Google Flights for the most up-to-date prices. ðŸ˜Š\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate \n",
    "from langchain.agents import initialize_agent                                   \n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.agents import AgentType\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\")\n",
    "\n",
    "search = TavilySearchResults()\n",
    "tools = [search]\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "# PREFIX = '''\n",
    "# Bing Bong\n",
    "# '''\n",
    "\n",
    "# FORMAT_INSTRUCTIONS = \"\"\"To use a tool, please use the following format:\n",
    "# '''\n",
    "# Thought: Do I need to use a tool? Yes\n",
    "# Action: the action to take, should be one of [{tool_names}]\n",
    "# Action Input: the input to the action\n",
    "# Observation: the result of the action\n",
    "# '''\n",
    "\n",
    "# When you have gathered all the information regarding AI algorithm, just write it to the user in the form of a blog post.\n",
    "\n",
    "# '''\n",
    "# Thought: Do I need to use a tool? No\n",
    "# AI: [write a blog post]\n",
    "# '''\n",
    "# \"\"\"\n",
    "\n",
    "# SUFFIX = '''\n",
    "\n",
    "# Begin!\n",
    "\n",
    "# Previous conversation history:\n",
    "# {chat_history}\n",
    "\n",
    "# Instructions: {input}\n",
    "# {agent_scratchpad}\n",
    "# '''\n",
    "\n",
    "\n",
    "agent = initialize_agent(\n",
    "    agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION,\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    verbose=False,\n",
    "    memory=memory,\n",
    "    handle_parsing_errors=True,\n",
    "    # return_intermediate_steps=True,\n",
    "    # agent_kwargs={\n",
    "        # 'prefix': PREFIX, \n",
    "    #     'format_instructions': FORMAT_INSTRUCTIONS,\n",
    "    #     'suffix': SUFFIX\n",
    "    # }\n",
    ")\n",
    "\n",
    "while True:\n",
    "    query = input(\"Query: \")\n",
    "    if query == \"exit\":\n",
    "        break\n",
    "    print(\"User: \", query)\n",
    "    response = agent.invoke({\"input\": query})\n",
    "    print(\"AI: \", response.get(\"output\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant is a large language model trained by OpenAI.\n",
      "\n",
      "Assistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
      "\n",
      "Assistant is constantly learning and improving, and its capabilities are constantly evolving. It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
      "\n",
      "Overall, Assistant is a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with a specific question or just want to have a conversation about a particular topic, Assistant is here to assist.\n",
      "\n",
      "TOOLS:\n",
      "------\n",
      "\n",
      "Assistant has access to the following tools:\n",
      "\n",
      "> tavily_search_results_json: A search engine optimized for comprehensive, accurate, and trusted results. Useful for when you need to answer questions about current events. Input should be a search query.\n",
      "\n",
      "To use a tool, please use the following format:\n",
      "\n",
      "```\n",
      "Thought: Do I need to use a tool? Yes\n",
      "Action: the action to take, should be one of [tavily_search_results_json]\n",
      "Action Input: the input to the action\n",
      "Observation: the result of the action\n",
      "```\n",
      "\n",
      "When you have a response to say to the Human, or if you do not need to use a tool, you MUST use the format:\n",
      "\n",
      "```\n",
      "Thought: Do I need to use a tool? No\n",
      "AI: [your response here]\n",
      "```\n",
      "\n",
      "Begin!\n",
      "\n",
      "Previous conversation history:\n",
      "{chat_history}\n",
      "\n",
      "New input: {input}\n",
      "{agent_scratchpad}\n"
     ]
    }
   ],
   "source": [
    "print(agent.agent.llm_chain.prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConversationBufferMemory(chat_memory=InMemoryChatMessageHistory(messages=[HumanMessage(content='Hey, how are you'), AIMessage(content='I am doing well, thank you for asking! How can I assist you today? ðŸ˜Š'), HumanMessage(content='Well i wanted to ask if you can tell me where the temperature is ?'), AIMessage(content='To tell you the temperature, I need to know your location. Could you please tell me where you are?'), HumanMessage(content='Well i am currently from jaipur'), AIMessage(content='It looks like Jaipur is experiencing sunny and warm weather right now. You can find more detailed weather information, including the current temperature, on websites like AccuWeather or Time and Date.'), HumanMessage(content='Can you tell me the temperature right now'), AIMessage(content='The current temperature in Jaipur is 26Â°C.'), HumanMessage(content='Okay from Jaipur to Chennai, what are the flight costs of economy flights?'), AIMessage(content='Based on current searches, the cheapest flight from Jaipur to Chennai is around â‚¹5415. However, prices vary depending on the date and airline. February is generally the cheapest month to fly.  I recommend checking flight comparison websites for the most up-to-date prices. ðŸ˜Š'), HumanMessage(content='I mean Jaipur to Japan'), AIMessage(content='Based on current searches, the cheapest flight from Jaipur to Japan is around â‚¹43,309. However, prices can vary depending on the date, airline, and availability. I recommend checking flight comparison websites like Skyscanner or Google Flights for the most up-to-date prices. ðŸ˜Š')]), return_messages=True, memory_key='chat_history')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AgentType.OPENAI_FUNCTIONS: 'openai-functions'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nilay Kumar\\Desktop\\langchain_app\\venv\\Lib\\site-packages\\langchain\\hub.py:86: DeprecationWarning: The `langchainhub sdk` is deprecated.\n",
      "Please use the `langsmith sdk` instead:\n",
      "  pip install langsmith\n",
      "Use the `pull_prompt` method.\n",
      "  res_dict = client.pull_repo(owner_repo_commit)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Prompt missing required variables: {'agent_scratchpad', 'tools'}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m tavily_tool \u001b[38;5;241m=\u001b[39m TavilySearchResults(max_results\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Create the agent using your custom prompt template and Tavily tool\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m agent \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_react_agent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtavily_tool\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_prompt_template\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Set up the agent executor\u001b[39;00m\n\u001b[0;32m     19\u001b[0m agent_executor \u001b[38;5;241m=\u001b[39m AgentExecutor(agent\u001b[38;5;241m=\u001b[39magent, tools\u001b[38;5;241m=\u001b[39m[tavily_tool], verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Nilay Kumar\\Desktop\\langchain_app\\venv\\Lib\\site-packages\\langchain\\agents\\react\\agent.py:117\u001b[0m, in \u001b[0;36mcreate_react_agent\u001b[1;34m(llm, tools, prompt, output_parser, tools_renderer, stop_sequence)\u001b[0m\n\u001b[0;32m    113\u001b[0m missing_vars \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtools\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool_names\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124magent_scratchpad\u001b[39m\u001b[38;5;124m\"\u001b[39m}\u001b[38;5;241m.\u001b[39mdifference(\n\u001b[0;32m    114\u001b[0m     prompt\u001b[38;5;241m.\u001b[39minput_variables \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(prompt\u001b[38;5;241m.\u001b[39mpartial_variables)\n\u001b[0;32m    115\u001b[0m )\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m missing_vars:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrompt missing required variables: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmissing_vars\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    119\u001b[0m prompt \u001b[38;5;241m=\u001b[39m prompt\u001b[38;5;241m.\u001b[39mpartial(\n\u001b[0;32m    120\u001b[0m     tools\u001b[38;5;241m=\u001b[39mtools_renderer(\u001b[38;5;28mlist\u001b[39m(tools)),\n\u001b[0;32m    121\u001b[0m     tool_names\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([t\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m tools]),\n\u001b[0;32m    122\u001b[0m )\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stop_sequence:\n",
      "\u001b[1;31mValueError\u001b[0m: Prompt missing required variables: {'agent_scratchpad', 'tools'}"
     ]
    }
   ],
   "source": [
    "from langchain.agents import AgentExecutor, create_react_agent\n",
    "from langchain_google_genai import GoogleGenerativeAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# Define your custom prompt template with required variables\n",
    "prompt = hub.pull(\"hwchase17/structured-chat-agent\")\n",
    "\n",
    "# Initialize the Google Gemini model\n",
    "llm = GoogleGenerativeAI(model=\"gemini-1.5-pro\", temperature=0)\n",
    "\n",
    "# Set up Tavily as a search tool\n",
    "tavily_tool = TavilySearchResults(max_results=10)\n",
    "\n",
    "# Create the agent using your custom prompt template and Tavily tool\n",
    "agent = create_react_agent(llm, tools=[tavily_tool], prompt=custom_prompt_template)\n",
    "\n",
    "# Set up the agent executor\n",
    "agent_executor = AgentExecutor(agent=agent, tools=[tavily_tool], verbose=True)\n",
    "\n",
    "# Invoke the agent with a query\n",
    "response = agent_executor.invoke({\"input\": \"What is Python?\"})\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
