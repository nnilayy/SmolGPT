{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Working Test"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import os\n","from dotenv import load_dotenv\n","from langchain_community.vectorstores import FAISS\n","from langchain_community.document_loaders import PyPDFLoader\n","from langchain.chains.question_answering import load_qa_chain\n","from langchain.text_splitter import RecursiveCharacterTextSplitter\n","from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI\n","\n","load_dotenv()\n","\n","# Loading The PDF File and Splitting it into Pages\n","loader = PyPDFLoader(\"2205.15868v1-CogVideo-Large-scale Pretraining for Text-to-Video.pdf\")\n","pages = loader.load_and_split()\n","\n","# Chunking the Pages into fixed size chunks\n","text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200, length_function=len)\n","documents = text_splitter.split_documents(pages)\n","\n","# Converting the documents into embeddings and storing them in a FAISS Vector Store\n","embedding = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n","vectordb = FAISS.from_documents(documents, embedding=embedding)\n","store_name = loader.source[:-4]\n","\n","query = (\"What is the main idea of the paper? WHat are the math formulas used in this paper\")\n","\n","docs = vectordb.similarity_search(query=query, k=5)\n","llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\")\n","chain = load_qa_chain(llm=llm, chain_type=\"stuff\")\n","response = chain.run(input_documents=docs, question=query)\n","print(response)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# # CHAINS\n","# https://python.langchain.com/v0.1/docs/modules/chains/\n","\n","# # DOCUMENT LOADERS\n","# https://python.langchain.com/v0.2/docs/integrations/document_loaders/\n"]},{"cell_type":"markdown","metadata":{},"source":["## Youtube Loader"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["url = \"https://www.youtube.com/watch?v=0AW6tWTRLeU\"\n","uploader = ScanDocuments()\n","data = uploader.upload_url(url)\n","documents = uploader.process_document(data)\n","\n","# -----------------------------------------------------------------------\n","# -----------------------------------------------------------------------\n","embedding = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n","llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\")\n","model = Model(llm, embedding)\n","\n","# -----------------------------------------------------------------------\n","# -----------------------------------------------------------------------\n","vector_store = VectorStore().create_vector_store(model.embeddings)\n","vector_store.add_documents(documents)\n","retriever = vector_store.as_retriever()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["query = \"What does Shayne say about Garlic Naan\"\n","\n","qa_chain = RetrievalQA.from_chain_type(\n","    llm = model.llm,\n","    chain_type = \"stuff\",\n","    retriever = retriever,\n","    return_source_documents = True,\n",")\n","qa_chain.invoke(query)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from langchain_core.documents import Document\n","\n","base_description_doc = documents[0]\n","\n","title = base_description_doc.metadata.get(\"title\")\n","description = base_description_doc.metadata.get(\"description\")\n","author = base_description_doc.metadata.get(\"author\")\n","date = base_description_doc.metadata.get(\"date\")\n","view_count = base_description_doc.metadata.get(\"view_count\")\n","\n","summary_doc = Document(\n","    metadata = base_description_doc.metadata,\n","    page_content = f\"\"\"This is a Youtube video Titled: {title}.\n","    This video was created by the Channel {author} on {date}. \n","    The video has {view_count} views. \n","    The Description of the video is: {description}\"\"\",\n",")\n","summary_doc\n","\n","new_documents = [summary_doc] + documents\n","new_documents"]},{"cell_type":"markdown","metadata":{},"source":["## Search"]},{"cell_type":"markdown","metadata":{},"source":["### Jina-ai"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import requests\n","from langchain_core.documents import Document\n","from langchain_community.vectorstores import FAISS\n","# -----------------------------------------------------------------------\n","# -----------------------------------------------------------------------\n","jina_search_url = \"https://s.jina.ai/\"\n","search_query = \"Tell me About Stable Diffusion CEO and Founder\"\n","response = requests.get(jina_search_url+search_query)\n","\n","uploader = ScanDocuments()  \n","text = Document(metadata={'source': '0AW6tWTRLeU'},page_content=str(response.text))\n","documents = uploader.process_document([text])\n","documents\n","# -----------------------------------------------------------------------\n","# -----------------------------------------------------------------------\n","embedding = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n","llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\")\n","model = Model(llm, embedding)\n","\n","# -----------------------------------------------------------------------\n","# -----------------------------------------------------------------------\n","# vectordb = FAISS.from_documents(documents, embedding=model.embeddings)\n","vectordb.add_documents(documents)\n","# vector_store = VectorStore().create_vector_store()\n","# vector_store.add_documents(documents)\n","retriever = vectordb.as_retriever()\n","# -----------------------------------------------------------------------\n","# -----------------------------------------------------------------------\n","qa_chain = RetrievalQA.from_chain_type(\n","    llm = model.llm,\n","    chain_type = \"stuff\",\n","    retriever = retriever,\n","    return_source_documents = True,\n",")\n","qa_chain.invoke(search_query)\n"]},{"cell_type":"markdown","metadata":{},"source":["### DuckDuckGo"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from langchain_community.tools import DuckDuckGoSearchRun\n","\n","search = DuckDuckGoSearchRun(max_results=5)\n","query = \"Tell me About Stable Diffusion CEO and Founder, Who is the new CEO of Stable Diffusion\"\n","results = search.invoke(query)\n","# -----------------------------------------------------------------------\n","# -----------------------------------------------------------------------\n","uploader = ScanDocuments()  \n","text = Document(metadata={'source': '0AW6tWTRLeU'},page_content=str(results))\n","documents = uploader.process_document([text])\n","documents\n","# -----------------------------------------------------------------------\n","# -----------------------------------------------------------------------\n","embedding = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n","llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\")\n","model = Model(llm, embedding)\n","# -----------------------------------------------------------------------\n","# -----------------------------------------------------------------------\n","vectordb.add_documents(documents)\n","retriever = vectordb.as_retriever()\n","# -----------------------------------------------------------------------\n","# -----------------------------------------------------------------------\n","qa_chain = RetrievalQA.from_chain_type(\n","    llm = model.llm,\n","    chain_type = \"stuff\",\n","    retriever = retriever,\n","    return_source_documents = True,\n",")\n","qa_chain.invoke(query)\n"]},{"cell_type":"markdown","metadata":{},"source":["### Wikipedia"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from langchain_community.tools import WikipediaQueryRun\n","from langchain_community.utilities import WikipediaAPIWrapper\n","wikipedia = WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper())\n","results = wikipedia.invoke(\"Tell me About Stable Diffusion CEO and Founder\")\n","results\n","# -----------------------------------------------------------------------\n","# -----------------------------------------------------------------------\n","uploader = ScanDocuments()  \n","text = Document(metadata={'source': '0AW6tWTRLeU'},page_content=str(results))\n","documents = uploader.process_document([text])\n","documents\n","# -----------------------------------------------------------------------\n","# -----------------------------------------------------------------------\n","embedding = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n","llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\")\n","model = Model(llm, embedding)\n","# -----------------------------------------------------------------------\n","# -----------------------------------------------------------------------\n","vectordb.add_documents(documents)\n","retriever = vectordb.as_retriever()\n","# -----------------------------------------------------------------------\n","# -----------------------------------------------------------------------\n","query = \"Tell me About Stable Diffusion CEO and Founder\"\n","qa_chain = RetrievalQA.from_chain_type(\n","    llm = model.llm,\n","    chain_type = \"stuff\",\n","    retriever = retriever,\n","    return_source_documents = True,\n",")\n","qa_chain.invoke(query)"]},{"cell_type":"markdown","metadata":{},"source":["### Serper Search"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from langchain_community.utilities import GoogleSerperAPIWrapper\n","from dotenv import load_dotenv\n","\n","load_dotenv() \n","\n","search = GoogleSerperAPIWrapper()\n","search.run(\"What are the Trending News in Paris Today\")\n"]},{"cell_type":"markdown","metadata":{},"source":["### Brave"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from langchain_community.tools import BraveSearch\n","tool = BraveSearch.from_api_key(search_kwargs={\"count\": 3})"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import nltk\n","nltk.download('punkt_tab')\n","nltk.download('averaged_perceptron_tagger_eng')"]},{"cell_type":"markdown","metadata":{},"source":["## Parallel Chains"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from langchain_community.utilities import DuckDuckGoSearchAPIWrapper, WikipediaAPIWrapper, GoogleSerperAPIWrapper\n","from langchain_core.runnables import RunnableParallel, RunnableMap\n","from dotenv import load_dotenv\n","from rich import print\n","# from langchain_openai import ChatOpenAI  # Assuming you want to use this for summarization\n","\n","load_dotenv() \n","\n","# Initialize search wrappers for each search engine\n","duckduckgo_search = DuckDuckGoSearchAPIWrapper()\n","wikipedia_search = WikipediaAPIWrapper()\n","serperapi_search = GoogleSerperAPIWrapper()\n","\n","# Create a parallel runnable for the searches\n","search_chain = RunnableParallel(\n","    duckduckgo=lambda query: duckduckgo_search.run(query),\n","    wikipedia=lambda query: wikipedia_search.run(query),\n","    serperapi=lambda query: serperapi_search.run(query),\n",")\n","\n","# Initialize the model for summarization\n","summarization_model = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\")\n","# ChatOpenAI(model=\"gpt-3.5-turbo\")  # Adjust as needed\n","\n","# Define a function to summarize the results\n","def summarize_results(results):\n","    prompt = f\"\"\"\n","    You have received the following search results:\n","\n","    DuckDuckGo: {results['duckduckgo']}\n","    Wikipedia: {results['wikipedia']}\n","    Google Serper: {results['serperapi']}\n","\n","    Please summarize the most accurate information from these results.\n","    \"\"\"\n","    summary = summarization_model.run(prompt)\n","    return summary\n","\n","# Combine the search and summarization into a single chain\n","combined_chain = RunnableMap(\n","    search_results=search_chain,\n","    summary=summarize_results\n",")\n","\n","# Run the combined chain with a query\n","query = \"What is the capital of France?\"\n","try:\n","    results = combined_chain.invoke({\"query\": query})\n","\n","    # Print the results from each search engine and the summary\n","    print(\"DuckDuckGo Results:\", results[\"search_results\"][\"duckduckgo\"])\n","    print(\"Wikipedia Results:\", results[\"search_results\"][\"wikipedia\"])\n","    print(\"Google Serper Results:\", results[\"search_results\"][\"serperapi\"])\n","    print(\"Summary of Most Accurate Information:\", results[\"summary\"])\n","except Exception as e:\n","    print(\"An error occurred during the search or summarization:\", str(e))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from langchain_community.utilities import DuckDuckGoSearchAPIWrapper, WikipediaAPIWrapper, GoogleSerperAPIWrapper\n","from langchain_core.runnables import RunnableParallel, RunnableMap\n","from dotenv import load_dotenv\n","# from langchain_openai import ChatOpenAI  # Assuming you want to use this for summarization\n","from rich import print\n","load_dotenv() \n","\n","# Initialize search wrappers for each search engine\n","duckduckgo_search = DuckDuckGoSearchAPIWrapper()\n","wikipedia_search = WikipediaAPIWrapper()\n","serperapi_search = GoogleSerperAPIWrapper()\n","\n","# Create a parallel runnable for the searches\n","search_chain = RunnableParallel(\n","    duckduckgo=duckduckgo_search.run,\n","    wikipedia=wikipedia_search.run,\n","    serperapi=serperapi_search.run,\n",")\n","\n","# Initialize the model for summarization\n","summarization_model = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\")\n","\n","# Define a function to summarize the results\n","def summarize_results(results, query):\n","    print(results)\n","    prompt = f\"\"\"\n","    You have received the following search results for the query: {query}\n","\n","    DuckDuckGo: {results['duckduckgo']}\n","    Wikipedia: {results['wikipedia']}\n","    Google Serper: {results['serperapi']}\n","\n","    Your Job is to provide only the most accurate information from these results for the given query.\n","    \"\"\"\n","    summary = summarization_model.invoke(prompt)\n","    return summary\n","\n","query = \"Giive me the Recipe for Chicken Tikka Masala and also the steps by step instructions\"\n","first_chain_result = search_chain.invoke(query)\n","second_chain_result = summarize_results(first_chain_result, query)\n","print(second_chain_result)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from langchain_community.utilities import DuckDuckGoSearchAPIWrapper, WikipediaAPIWrapper, GoogleSerperAPIWrapper\n","from langchain_core.runnables import RunnableParallel, RunnableMap\n","from dotenv import load_dotenv\n","# from langchain_openai import ChatOpenAI  # Assuming you want to use this for summarization\n","from rich import print\n","load_dotenv() \n","\n","# Initialize search wrappers for each search engine\n","duckduckgo_search = DuckDuckGoSearchAPIWrapper()\n","wikipedia_search = WikipediaAPIWrapper()\n","serperapi_search = GoogleSerperAPIWrapper()\n","\n","# Create a parallel runnable for the searches\n","search_chain = RunnableParallel(\n","    duckduckgo=duckduckgo_search.run,\n","    wikipedia=wikipedia_search.run,\n","    serperapi=serperapi_search.run,\n",")\n","\n","# Initialize the model for summarization\n","summarization_model = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\")\n","\n","# Define a function to summarize the results\n","def summarize_results(results, query):\n","    print(results)\n","    prompt = f\"\"\"\n","    You have received the following search results for the query: {query}\n","\n","    DuckDuckGo: {results['duckduckgo']}\n","    Wikipedia: {results['wikipedia']}\n","    Google Serper: {results['serperapi']}\n","\n","    Your Job is to provide only the most accurate information from these results for the given query.\n","    \"\"\"\n","    summary = summarization_model.invoke(prompt)\n","    return summary\n","\n","query = \"What are the Harmful effects of Smoking\"\n","first_chain_result = search_chain.invoke(query)\n","\n","\n","second_chain_result = summarize_results(first_chain_result, query)\n","print(second_chain_result)"]},{"cell_type":"markdown","metadata":{},"source":["## Agent"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["INFO:root:Loading FAISS Vector Store\n","INFO:root:Added 65 documents to the vector store.\n"]}],"source":["import warnings\n","from langchain import hub\n","from dotenv import load_dotenv\n","from langchain_groq import ChatGroq\n","\n","from langchain.agents import create_react_agent\n","from langchain.agents.agent import AgentExecutor\n","from langchain.memory import ConversationBufferMemory\n","from langchain_community.tools.tavily_search import TavilySearchResults\n","from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n","\n","from helper_classes.model import Model\n","from helper_classes.search import Search\n","from helper_classes.vector_store import VectorStore\n","from helper_classes.scan_documents import ScanDocuments\n","from helper_classes.converser import Converser\n","\n","warnings.filterwarnings(\"ignore\")\n","\n","load_dotenv()  \n","\n","# DOCUMENTS\n","uploader = ScanDocuments()\n","data = uploader.upload_single_file(\"files/2205.15868v1-CogVideo-Large-scale Pretraining for Text-to-Video.pdf\")\n","documents = uploader.process_document(data)\n","\n","\n","# LLMS AND EMBEDDINGS\n","embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n","# llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\")\n","llm = ChatGroq(model=\"mixtral-8x7b-32768\")\n","model = Model(llm, embeddings)\n","\n","\n","# VECTOR STORE\n","vector_store = VectorStore(model, search_num_docs=10)\n","vector_store.add_documents(documents)\n","\n","\n","# TOOLS\n","search_engine_tool = TavilySearchResults()\n","tools = [search_engine_tool, vector_store.vectordb_search_tool]\n","\n","\n","memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n","prompt = hub.pull(\"hwchase17/react\")\n","\n","# AGENT\n","agent = create_react_agent(llm=llm, tools=tools, prompt=prompt)\n","agent_executor = AgentExecutor.from_agent_and_tools(\n","    agent=agent,\n","    tools=tools,\n","    llm=llm,\n","    max_iterations=15,\n","    verbose=True,\n","    memory=memory,\n","    handle_parsing_errors=True,\n","    return_intermediate_steps=False,\n",")"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["converser = Converser(agent_executor)\n","converser.converse()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["agent_executor = AgentExecutor.from_agent_and_tools(\n","    agent=agent,\n","    tools=tools,\n","    llm=llm,\n","    max_iterations=15,\n","    verbose=True,\n","    memory=memory,\n","    handle_parsing_errors=True,\n","    return_intermediate_steps=False,\n","    # agent_kwargs={\n","        # 'prefix': PREFIX, \n","    #     'format_instructions': FORMAT_INSTRUCTIONS,\n","    #     'suffix': SUFFIX\n","    # }\n",")\n","\n","# agent_executor.invoke({\"input\": \"Can you Explain in Detail The idea behind the paper CogVideo\"})\n","# llm.invoke(\"What is the main idea of the paper? WHat are the math formulas used in this paper\")\n","# vector_store.vectordb_search_tool.invoke(\"What is the main idea of the paper? WHat are the math formulas used in this paper\")\n","# vector_store.qa_chain.invoke(\"What is the main idea of the paper? WHat are the math formulas used in this paper\")"]}],"metadata":{"kernelspec":{"display_name":"venv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.4"}},"nbformat":4,"nbformat_minor":2}
