{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Working Test"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import os\n","from dotenv import load_dotenv\n","from langchain_community.vectorstores import FAISS\n","from langchain_community.document_loaders import PyPDFLoader\n","from langchain.chains.question_answering import load_qa_chain\n","from langchain.text_splitter import RecursiveCharacterTextSplitter\n","from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI\n","\n","load_dotenv()\n","\n","# Loading The PDF File and Splitting it into Pages\n","loader = PyPDFLoader(\"2205.15868v1-CogVideo-Large-scale Pretraining for Text-to-Video.pdf\")\n","pages = loader.load_and_split()\n","\n","# Chunking the Pages into fixed size chunks\n","text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200, length_function=len)\n","documents = text_splitter.split_documents(pages)\n","\n","# Converting the documents into embeddings and storing them in a FAISS Vector Store\n","embedding = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n","vectordb = FAISS.from_documents(documents, embedding=embedding)\n","store_name = loader.source[:-4]\n","\n","query = (\"What is the main idea of the paper? WHat are the math formulas used in this paper\")\n","\n","docs = vectordb.similarity_search(query=query, k=5)\n","llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\")\n","chain = load_qa_chain(llm=llm, chain_type=\"stuff\")\n","response = chain.run(input_documents=docs, question=query)\n","print(response)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# # CHAINS\n","# https://python.langchain.com/v0.1/docs/modules/chains/\n","\n","# # DOCUMENT LOADERS\n","# https://python.langchain.com/v0.2/docs/integrations/document_loaders/\n"]},{"cell_type":"markdown","metadata":{},"source":["## Testing Class"]},{"cell_type":"code","execution_count":101,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["files/UNIT-2.pptx\n"]}],"source":["import os\n","import logging\n","from langchain.chains import RetrievalQA\n","from langchain_core.documents import Document\n","from langchain_community.vectorstores import FAISS\n","from langchain_community.document_loaders import (PyPDFLoader, \n","                                                  Docx2txtLoader, \n","                                                  UnstructuredExcelLoader, \n","                                                  UnstructuredPowerPointLoader,\n","                                                  TextLoader,\n","                                                  CSVLoader,\n","                                                  YoutubeLoader)\n","from langchain.text_splitter import RecursiveCharacterTextSplitter\n","\n","\n","files = [\n","\"files/2205.15868v1-CogVideo-Large-scale Pretraining for Text-to-Video.pdf\",\n","'files/IM-Report.docx',\n","\"files/UNIT-2.pptx\",\n","\"files/Hperverge OT list final.xlsx\",\n","\"files/hey.txt\",\n","\"files/test.md\",\n","]\n","file_path = files[2]\n","print(file_path)\n","\n","\n","\n","logging.basicConfig(level=logging.INFO)\n","\n","\n","\n","class Model:\n","    def __init__(self, llm, embeddings):\n","        self.llm = llm\n","        self.embeddings = embeddings\n","\n","\n","class ScanDocuments:\n","    def __init__(self):\n","        pass\n","    \n","    def upload_single_file(self, path):\n","        if path.endswith(\".pdf\"):\n","            loader = PyPDFLoader(path)\n","        elif path.endswith(\".docx\"):\n","            loader = Docx2txtLoader(path)\n","        elif path.endswith(\".xlsx\"):\n","            loader = UnstructuredExcelLoader(path, encoding = 'UTF-8')\n","        elif path.endswith(\".pptx\"):\n","            loader = UnstructuredPowerPointLoader(path, encoding = 'UTF-8')\n","        elif path.endswith(\".txt\") or path.endswith(\".md\"):\n","            loader = TextLoader(path, encoding = 'UTF-8')\n","        elif path.endswith(\".csv\"):\n","            loader = CSVLoader(path, encoding = 'UTF-8')\n","        data = loader.load_and_split()\n","        return data\n","    \n","    def upload_url(self, url):\n","        if \"www.youtube.com\" in url:\n","            loader =  YoutubeLoader.from_youtube_url(url,add_video_info=True)\n","        data = loader.load_and_split()\n","        return data\n","        \n","    def upload_zip_file(self):\n","        pass\n","    def process_document(self, data):\n","        doc_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200, length_function=len)\n","        documents = doc_splitter.split_documents(data)\n","        return documents\n","\n","\n","class VectorStore:\n","    def __init__(self, model, search_num_docs):\n","        self.model = model\n","        self.search_num_docs = search_num_docs\n","        self.vectordb = self.initialize_vector_store()\n","        self.retriever = self.vectordb.as_retriever(search_kwargs={\"k\": self.search_num_docs})\n","        self.qa_chain = self.setup_qa_chain()\n","\n","    def initialize_vector_store(self):\n","        \"\"\"Initialize or load the FAISS vector database.\"\"\"\n","        if not os.path.exists(\"./faiss_vectordb\"):\n","            logging.info(\"Creating FAISS Vector Store\")\n","            vectordb = FAISS.from_documents(documents=[Document(page_content=\"\")],\n","                                            embedding=self.model.embeddings)\n","            vectordb.save_local(\"faiss_vectordb\")\n","        else:\n","            logging.info(\"Loading FAISS Vector Store\")\n","            vectordb = FAISS.load_local(\"faiss_vectordb\",\n","                                         embeddings=self.model.embeddings, \n","                                         allow_dangerous_deserialization=True)\n","        return vectordb\n","\n","    def setup_qa_chain(self):\n","        \"\"\"Set up the QA chain using the retriever.\"\"\"\n","        return RetrievalQA.from_chain_type(\n","            llm=self.model.llm,\n","            chain_type=\"stuff\",\n","            retriever=self.retriever,\n","            return_source_documents=True\n","        )\n","\n","    def add_documents(self, documents):\n","        \"\"\"Add documents to the vector database.\"\"\"\n","        self.vectordb.add_documents(documents)\n","        logging.info(f\"Added {len(documents)} documents to the vector store.\")\n","\n","class Search:\n","    def __init__(self, Model):\n","        self.model = Model\n","        self.wikipeadia = None\n","        self.duckduckgo = None\n","        self.jinai = None\n","        self.googleserper = None\n","        # self.bing = None\n","        # self.brave = None\n","        self.base_engine = self.duckduckgo\n","\n","    def search_base_engine(self, query):\n","        results = self.base_engine.search(query)\n","        return results\n","\n","    def search_multi_engines(self, query):\n","        wikipedia_results = self.wikipeadia.run(query)\n","        duckduckgo_results = self.duckduckgo.run(query)\n","        jina_ai_results = self.jinai.run(query)\n","        google_serper_results = self.googleserper.run(query)\n","        \n","        multi_engine_results = {\n","            \"wikipedia\": wikipedia_results,\n","            \"duckduckgo\": duckduckgo_results,\n","            \"jina_ai\": jina_ai_results,\n","            \"google_serper\": google_serper_results\n","        }\n","        return multi_engine_results\n","\n","    def search_best_sites_for_query(self, query):\n","        prompt = f\"\"\"You are a helpful Assistant, You would be Provided a Query by the user, You Have to take the \n","        query, extract the main idea behind the query and provide the a sentence which would say:\n","\n","        Best Sites to Inquire more about query\n","\n","        For Example:\n","\n","        User: What is the temperature in Japan?\n","        Answer: sites to find about weather conditions of countries?:\n","\n","        Now Create the Reverse Query for the given Query by the user:\n","        User:{query}\n","        Answer:\n","        \"\"\"\n","        search_query = self.model.llm.invoke(prompt)\n","        sites = \"https://s.jina.ai/\"+search_query\n","        return sites        \n","\n","# ------------------------------------------------------------------------------\n","# ------------------------------------------------------------------------------\n","# Google Drive: [https://python.langchain.com/v0.2/docs/integrations/document_loaders/google_drive]\n","# BibTeX: [https://python.langchain.com/v0.2/docs/integrations/document_loaders/bibtex]\n","# ArxivLoader, []\n"]},{"cell_type":"code","execution_count":103,"metadata":{},"outputs":[{"data":{"text/plain":["<langchain_community.vectorstores.faiss.FAISS at 0x17a80c94260>"]},"execution_count":103,"metadata":{},"output_type":"execute_result"}],"source":[]},{"cell_type":"code","execution_count":137,"metadata":{},"outputs":[{"data":{"text/plain":["'Answer: sites to find out the current time in different cities/timezones? \\n'"]},"execution_count":137,"metadata":{},"output_type":"execute_result"}],"source":["searcher = Search(model)\n","response = searcher.search_best_sites_for_query(\"Time in Paris\").content\n","response.split(\"Answer:\")[-1].split(\"\\n\")[0]"]},{"cell_type":"markdown","metadata":{},"source":["## Sample test"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["url = \"https://www.youtube.com/watch?v=0AW6tWTRLeU\"\n","uploader = ScanDocuments()\n","data = uploader.upload_url(url)\n","documents = uploader.process_document(data)\n","\n","# -----------------------------------------------------------------------\n","# -----------------------------------------------------------------------\n","embedding = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n","llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\")\n","model = Model(llm, embedding)\n","\n","# -----------------------------------------------------------------------\n","# -----------------------------------------------------------------------\n","vector_store = VectorStore().create_vector_store(model.embeddings)\n","vector_store.add_documents(documents)\n","retriever = vector_store.as_retriever()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["query = \"What does Shayne say about Garlic Naan\"\n","\n","qa_chain = RetrievalQA.from_chain_type(\n","    llm = model.llm,\n","    chain_type = \"stuff\",\n","    retriever = retriever,\n","    return_source_documents = True,\n",")\n","qa_chain.invoke(query)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from langchain_core.documents import Document\n","\n","base_description_doc = documents[0]\n","\n","title = base_description_doc.metadata.get(\"title\")\n","description = base_description_doc.metadata.get(\"description\")\n","author = base_description_doc.metadata.get(\"author\")\n","date = base_description_doc.metadata.get(\"date\")\n","view_count = base_description_doc.metadata.get(\"view_count\")\n","\n","summary_doc = Document(\n","    metadata = base_description_doc.metadata,\n","    page_content = f\"\"\"This is a Youtube video Titled: {title}.\n","    This video was created by the Channel {author} on {date}. \n","    The video has {view_count} views. \n","    The Description of the video is: {description}\"\"\",\n",")\n","summary_doc\n","\n","new_documents = [summary_doc] + documents\n","new_documents"]},{"cell_type":"markdown","metadata":{},"source":["## Search"]},{"cell_type":"markdown","metadata":{},"source":["### Jina-ai"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import requests\n","from langchain_core.documents import Document\n","from langchain_community.vectorstores import FAISS\n","# -----------------------------------------------------------------------\n","# -----------------------------------------------------------------------\n","jina_search_url = \"https://s.jina.ai/\"\n","search_query = \"Tell me About Stable Diffusion CEO and Founder\"\n","response = requests.get(jina_search_url+search_query)\n","\n","uploader = ScanDocuments()  \n","text = Document(metadata={'source': '0AW6tWTRLeU'},page_content=str(response.text))\n","documents = uploader.process_document([text])\n","documents\n","# -----------------------------------------------------------------------\n","# -----------------------------------------------------------------------\n","embedding = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n","llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\")\n","model = Model(llm, embedding)\n","\n","# -----------------------------------------------------------------------\n","# -----------------------------------------------------------------------\n","# vectordb = FAISS.from_documents(documents, embedding=model.embeddings)\n","vectordb.add_documents(documents)\n","# vector_store = VectorStore().create_vector_store()\n","# vector_store.add_documents(documents)\n","retriever = vectordb.as_retriever()\n","# -----------------------------------------------------------------------\n","# -----------------------------------------------------------------------\n","qa_chain = RetrievalQA.from_chain_type(\n","    llm = model.llm,\n","    chain_type = \"stuff\",\n","    retriever = retriever,\n","    return_source_documents = True,\n",")\n","qa_chain.invoke(search_query)\n"]},{"cell_type":"markdown","metadata":{},"source":["### DuckDuckGo"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from langchain_community.tools import DuckDuckGoSearchRun\n","\n","search = DuckDuckGoSearchRun(max_results=5)\n","query = \"Tell me About Stable Diffusion CEO and Founder, Who is the new CEO of Stable Diffusion\"\n","results = search.invoke(query)\n","# -----------------------------------------------------------------------\n","# -----------------------------------------------------------------------\n","uploader = ScanDocuments()  \n","text = Document(metadata={'source': '0AW6tWTRLeU'},page_content=str(results))\n","documents = uploader.process_document([text])\n","documents\n","# -----------------------------------------------------------------------\n","# -----------------------------------------------------------------------\n","embedding = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n","llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\")\n","model = Model(llm, embedding)\n","# -----------------------------------------------------------------------\n","# -----------------------------------------------------------------------\n","vectordb.add_documents(documents)\n","retriever = vectordb.as_retriever()\n","# -----------------------------------------------------------------------\n","# -----------------------------------------------------------------------\n","qa_chain = RetrievalQA.from_chain_type(\n","    llm = model.llm,\n","    chain_type = \"stuff\",\n","    retriever = retriever,\n","    return_source_documents = True,\n",")\n","qa_chain.invoke(query)\n"]},{"cell_type":"markdown","metadata":{},"source":["### Wikipedia"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from langchain_community.tools import WikipediaQueryRun\n","from langchain_community.utilities import WikipediaAPIWrapper\n","wikipedia = WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper())\n","results = wikipedia.run(\"Tell me About Stable Diffusion CEO and Founder\")\n","results\n","# -----------------------------------------------------------------------\n","# -----------------------------------------------------------------------\n","uploader = ScanDocuments()  \n","text = Document(metadata={'source': '0AW6tWTRLeU'},page_content=str(results))\n","documents = uploader.process_document([text])\n","documents\n","# -----------------------------------------------------------------------\n","# -----------------------------------------------------------------------\n","embedding = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n","llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\")\n","model = Model(llm, embedding)\n","# -----------------------------------------------------------------------\n","# -----------------------------------------------------------------------\n","vectordb.add_documents(documents)\n","retriever = vectordb.as_retriever()\n","# -----------------------------------------------------------------------\n","# -----------------------------------------------------------------------\n","query = \"Tell me About Stable Diffusion CEO and Founder\"\n","qa_chain = RetrievalQA.from_chain_type(\n","    llm = model.llm,\n","    chain_type = \"stuff\",\n","    retriever = retriever,\n","    return_source_documents = True,\n",")\n","qa_chain.invoke(query)"]},{"cell_type":"markdown","metadata":{},"source":["### Serper Search"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from langchain_community.utilities import GoogleSerperAPIWrapper\n","from dotenv import load_dotenv\n","\n","load_dotenv() \n","\n","search = GoogleSerperAPIWrapper()\n","search.run(\"What are the Trending News in Paris Today\")\n"]},{"cell_type":"markdown","metadata":{},"source":["### Brave"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from langchain_community.tools import BraveSearch\n","tool = BraveSearch.from_api_key(search_kwargs={\"count\": 3})"]},{"cell_type":"markdown","metadata":{},"source":["### SearchXGN"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from langchain_community.utilities import SearxSearchWrapper\n","searx = SearxSearchWrapper(searx_host=\"http://localhost:8888\",\n","                                        unsecure=True)\n","searx.run(\"What are the Trending News in Paris Today\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from langchain.vectorstores import Chroma\n","from langchain.chains import RetrievalQA\n","from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI \n","\n","# documents =\n","llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\")\n","embedding = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n","\n","\n","vectordb = Chroma.from_documents(documents, \n","                                 embedding=embedding,\n","                                 persist_directory=\"chroma\"\n","                                 )\n","\n","retriever = vectordb.as_retriever(\n","    search_type = \"similarity\",\n","    search_kwargs = {'k':3})\n","\n","qa_chain = RetrievalQA.from_chain_type(\n","    llm = llm,\n","    chain_type = \"stuff\",\n","    retriever = vectordb.as_retriever(),\n","    # return_source_documents = True,\n",")\n","\n","query = \"What is video about?\"\n","docs = retriever.get_relevant_documents(query)\n","qa_chain.invoke(query, documents = docs)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# -----------------------------------------------------------------------------------------\n","# -----------------------------------------------------------------------------------------\n","# from langchain.vectorstores import Chroma\n","# from langchain.chains import RetrievalQA\n","\n","# vectordb  = FAISS.from_documents(documents, embedding=embedding)\n","# qa_chain = RetrievalQA.from_chain_type(\n","#     llm = llm,\n","#     chain_type = \"stuff\",\n","#     retriever = vectordb.as_retriever(),\n","# )\n","\n","# query = \"What is the main idea of the paper? WHat are the math formulas used in this paper\"\t\n","# results = qa_chain.invoke(query)\n","# vectordb.save_local(\"vectordb\")\n","\n","\n","# vectordb.delete_collection()\n","# qa_chain.combine_documents_chain_.llm_chain.prompt.messages[0].prompt.template"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from langchain_community.document_loaders import YoutubeLoader\n","\n","youtube_url = \"https://www.youtube.com/watch?v=QsYGlZkevEg\"\n","loader = YoutubeLoader.from_youtube_url(youtube_url,add_video_info=True)\n","# transcript = loader.load()\n","# transcript\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import nltk\n","nltk.download('punkt_tab')\n","nltk.download('averaged_perceptron_tagger_eng')"]},{"cell_type":"markdown","metadata":{},"source":["## Parallel Chains"]},{"cell_type":"code","execution_count":73,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["An error occurred during the search or summarization: https://links.duckduckgo.com/d.js TypeError: argument 'params': 'dict' object cannot be converted to 'PyString'\n"]}],"source":["from langchain_community.utilities import DuckDuckGoSearchAPIWrapper, WikipediaAPIWrapper, GoogleSerperAPIWrapper\n","from langchain_core.runnables import RunnableParallel, RunnableMap\n","from dotenv import load_dotenv\n","from rich import print\n","# from langchain_openai import ChatOpenAI  # Assuming you want to use this for summarization\n","\n","load_dotenv() \n","\n","# Initialize search wrappers for each search engine\n","duckduckgo_search = DuckDuckGoSearchAPIWrapper()\n","wikipedia_search = WikipediaAPIWrapper()\n","serperapi_search = GoogleSerperAPIWrapper()\n","\n","# Create a parallel runnable for the searches\n","search_chain = RunnableParallel(\n","    duckduckgo=lambda query: duckduckgo_search.run(query),\n","    wikipedia=lambda query: wikipedia_search.run(query),\n","    serperapi=lambda query: serperapi_search.run(query),\n",")\n","\n","# Initialize the model for summarization\n","summarization_model = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\")\n","# ChatOpenAI(model=\"gpt-3.5-turbo\")  # Adjust as needed\n","\n","# Define a function to summarize the results\n","def summarize_results(results):\n","    prompt = f\"\"\"\n","    You have received the following search results:\n","\n","    DuckDuckGo: {results['duckduckgo']}\n","    Wikipedia: {results['wikipedia']}\n","    Google Serper: {results['serperapi']}\n","\n","    Please summarize the most accurate information from these results.\n","    \"\"\"\n","    summary = summarization_model.run(prompt)\n","    return summary\n","\n","# Combine the search and summarization into a single chain\n","combined_chain = RunnableMap(\n","    search_results=search_chain,\n","    summary=summarize_results\n",")\n","\n","# Run the combined chain with a query\n","query = \"What is the capital of France?\"\n","try:\n","    results = combined_chain.invoke({\"query\": query})\n","\n","    # Print the results from each search engine and the summary\n","    print(\"DuckDuckGo Results:\", results[\"search_results\"][\"duckduckgo\"])\n","    print(\"Wikipedia Results:\", results[\"search_results\"][\"wikipedia\"])\n","    print(\"Google Serper Results:\", results[\"search_results\"][\"serperapi\"])\n","    print(\"Summary of Most Accurate Information:\", results[\"summary\"])\n","except Exception as e:\n","    print(\"An error occurred during the search or summarization:\", str(e))"]},{"cell_type":"code","execution_count":90,"metadata":{},"outputs":[{"ename":"ImportError","evalue":"cannot import name 'Pretty' from 'rich' (c:\\Users\\Nilay Kumar\\Desktop\\langchain_app\\venv\\Lib\\site-packages\\rich\\__init__.py)","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)","Cell \u001b[1;32mIn[90], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrich\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;28mprint\u001b[39m, Pretty\n\u001b[0;32m      3\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhello\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(text)\n","\u001b[1;31mImportError\u001b[0m: cannot import name 'Pretty' from 'rich' (c:\\Users\\Nilay Kumar\\Desktop\\langchain_app\\venv\\Lib\\site-packages\\rich\\__init__.py)"]}],"source":["from rich import print, Pretty\n","\n","text = \"hello\"\n","print(text)"]},{"cell_type":"code","execution_count":112,"metadata":{},"outputs":[{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n","    <span style=\"color: #008000; text-decoration-color: #008000\">'duckduckgo'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'While the tikka masala cooks, grill your chicken tikka. Thread the chicken on to the skewers and</span>\n","<span style=\"color: #008000; text-decoration-color: #008000\">place them on a prepared tray. Place the tray in the middle rack, in a preheated oven at 240 C or 460 F for 9 to 10</span>\n","<span style=\"color: #008000; text-decoration-color: #008000\">mins. 15. Later turn them with the help of a tong and bake for another 9 to 10 mins. Now cover the lid, cook on </span>\n","<span style=\"color: #008000; text-decoration-color: #008000\">medium-low for 15-20 minutes, stir occasionally, Cook until it reaches that consistency as shown on video. Next </span>\n","<span style=\"color: #008000; text-decoration-color: #008000\">take out the whole spices. Add the Chicken Tikka and mix well. Now add ¼ water, and cover the lid let it cook on </span>\n","<span style=\"color: #008000; text-decoration-color: #008000\">low for 4-5 minutes. Add honey and heavy whipping cream and mix well. Melt butter in a large skillet or dutch oven </span>\n","<span style=\"color: #008000; text-decoration-color: #008000\">over medium heat. Saute garlic for 1 minute. Season with cumin, paprika, garam masala, chili powder, and salt. Stir</span>\n","<span style=\"color: #008000; text-decoration-color: #008000\">in tomato sauce and cream. Simmer on medium low heat until sauce thickens, about 20 minutes. Add grilled chicken to</span>\n","<span style=\"color: #008000; text-decoration-color: #008000\">the sauce, and simmer for 5 more minutes. Marinate the chicken: In a large bowl, mix the yogurt, lemon juice, oil, </span>\n","<span style=\"color: #008000; text-decoration-color: #008000\">ginger, garlic, chili powder, cumin, garam masala, turmeric, and cayenne pepper until smooth. Pat the chicken </span>\n","<span style=\"color: #008000; text-decoration-color: #008000\">pieces dry, then add them to the bowl and mix until they are very well coated. Cover and chill for at least 3 </span>\n","<span style=\"color: #008000; text-decoration-color: #008000\">hours, or overnight. Cover the bowl and leave it in the refrigerator for at least six hours. The longer, the better</span>\n","<span style=\"color: #008000; text-decoration-color: #008000\">for the spices to develop in the meat. When ready to cook, put the meat on skewers and place them on a baking tray.</span>\n","<span style=\"color: #008000; text-decoration-color: #008000\">Cook the chicken tikka in a grilled oven, ordinary oven, air fryer, or instant pot at 350°F/ 180°C.'</span>,\n","    <span style=\"color: #008000; text-decoration-color: #008000\">'wikipedia'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'No good Wikipedia Search Result was found'</span>,\n","    <span style=\"color: #008000; text-decoration-color: #008000\">'serperapi'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Chicken tikka masala is a popular curried dish made with boneless chicken, ground spices, onions,</span>\n","<span style=\"color: #008000; text-decoration-color: #008000\">tomatoes, cream and herbs. Instructions · In a bowl, combine chicken with all of the ingredients for the chicken </span>\n","<span style=\"color: #008000; text-decoration-color: #008000\">marinade; let marinate for 10 minutes to an hour (or ... Missing: steps | Show results with:steps. Slow Cooker </span>\n","<span style=\"color: #008000; text-decoration-color: #008000\">Chicken Tikka Masala: Same ingredients and instructions for steps 1 and 2. At step 3, add chicken, masala paste, </span>\n","<span style=\"color: #008000; text-decoration-color: #008000\">and tomato puree to the slow cooker ... Ingredients · 1 cup basmati rice · 1 ½ pounds boneless skinless chicken </span>\n","<span style=\"color: #008000; text-decoration-color: #008000\">thighs, cut into 1-inch chunks · Kosher salt and freshly ground black ... Missing: steps | Show results with:steps.</span>\n","<span style=\"color: #008000; text-decoration-color: #008000\">Ingredients · 1 cup yogurt · 1 tablespoon lemon juice · 4 teaspoons ground cumin, divided · 1 teaspoon ground </span>\n","<span style=\"color: #008000; text-decoration-color: #008000\">cinnamon · 2 teaspoons cayenne pepper. Missing: steps | Show results with:steps. Ingredients · 3 boneless, skinless</span>\n","<span style=\"color: #008000; text-decoration-color: #008000\">chicken breasts · ½ cup plain yogurt · 2 tablespoons lemon juice · 6 cloves garlic, minced · 1 tablespoon minced </span>\n","<span style=\"color: #008000; text-decoration-color: #008000\">... Missing: steps instructions. We start by marinating the chicken in a mixture of yogurt and spices. It needs to </span>\n","<span style=\"color: #008000; text-decoration-color: #008000\">marinade for at least a couple of hours, to really tenderize ... Step-by-Step Instructions ... Begin by chopping </span>\n","<span style=\"color: #008000; text-decoration-color: #008000\">the chicken breasts into chunks. Feel free to substitute boneless skinless chicken thighs if you ... Missing: steps</span>\n","<span style=\"color: #008000; text-decoration-color: #008000\">| Show results with:steps. A made-from-scratch Chicken Tikka Masala recipe with the signature yoghurt marinated </span>\n","<span style=\"color: #008000; text-decoration-color: #008000\">chargrilled chicken smothered in an incredible spice ... ... chicken tikka masala then this recipe is the right </span>\n","<span style=\"color: #008000; text-decoration-color: #008000\">choice for you. Today I will show you step ... Duration: 9:35. Posted: Jul 24, 2020.'</span>\n","<span style=\"font-weight: bold\">}</span>\n","</pre>\n"],"text/plain":["\u001b[1m{\u001b[0m\n","    \u001b[32m'duckduckgo'\u001b[0m: \u001b[32m'While the tikka masala cooks, grill your chicken tikka. Thread the chicken on to the skewers and\u001b[0m\n","\u001b[32mplace them on a prepared tray. Place the tray in the middle rack, in a preheated oven at 240 C or 460 F for 9 to 10\u001b[0m\n","\u001b[32mmins. 15. Later turn them with the help of a tong and bake for another 9 to 10 mins. Now cover the lid, cook on \u001b[0m\n","\u001b[32mmedium-low for 15-20 minutes, stir occasionally, Cook until it reaches that consistency as shown on video. Next \u001b[0m\n","\u001b[32mtake out the whole spices. Add the Chicken Tikka and mix well. Now add ¼ water, and cover the lid let it cook on \u001b[0m\n","\u001b[32mlow for 4-5 minutes. Add honey and heavy whipping cream and mix well. Melt butter in a large skillet or dutch oven \u001b[0m\n","\u001b[32mover medium heat. Saute garlic for 1 minute. Season with cumin, paprika, garam masala, chili powder, and salt. Stir\u001b[0m\n","\u001b[32min tomato sauce and cream. Simmer on medium low heat until sauce thickens, about 20 minutes. Add grilled chicken to\u001b[0m\n","\u001b[32mthe sauce, and simmer for 5 more minutes. Marinate the chicken: In a large bowl, mix the yogurt, lemon juice, oil, \u001b[0m\n","\u001b[32mginger, garlic, chili powder, cumin, garam masala, turmeric, and cayenne pepper until smooth. Pat the chicken \u001b[0m\n","\u001b[32mpieces dry, then add them to the bowl and mix until they are very well coated. Cover and chill for at least 3 \u001b[0m\n","\u001b[32mhours, or overnight. Cover the bowl and leave it in the refrigerator for at least six hours. The longer, the better\u001b[0m\n","\u001b[32mfor the spices to develop in the meat. When ready to cook, put the meat on skewers and place them on a baking tray.\u001b[0m\n","\u001b[32mCook the chicken tikka in a grilled oven, ordinary oven, air fryer, or instant pot at 350°F/ 180°C.'\u001b[0m,\n","    \u001b[32m'wikipedia'\u001b[0m: \u001b[32m'No good Wikipedia Search Result was found'\u001b[0m,\n","    \u001b[32m'serperapi'\u001b[0m: \u001b[32m'Chicken tikka masala is a popular curried dish made with boneless chicken, ground spices, onions,\u001b[0m\n","\u001b[32mtomatoes, cream and herbs. Instructions · In a bowl, combine chicken with all of the ingredients for the chicken \u001b[0m\n","\u001b[32mmarinade; let marinate for 10 minutes to an hour \u001b[0m\u001b[32m(\u001b[0m\u001b[32mor ... Missing: steps | Show results with:steps. Slow Cooker \u001b[0m\n","\u001b[32mChicken Tikka Masala: Same ingredients and instructions for steps 1 and 2. At step 3, add chicken, masala paste, \u001b[0m\n","\u001b[32mand tomato puree to the slow cooker ... Ingredients · 1 cup basmati rice · 1 ½ pounds boneless skinless chicken \u001b[0m\n","\u001b[32mthighs, cut into 1-inch chunks · Kosher salt and freshly ground black ... Missing: steps | Show results with:steps.\u001b[0m\n","\u001b[32mIngredients · 1 cup yogurt · 1 tablespoon lemon juice · 4 teaspoons ground cumin, divided · 1 teaspoon ground \u001b[0m\n","\u001b[32mcinnamon · 2 teaspoons cayenne pepper. Missing: steps | Show results with:steps. Ingredients · 3 boneless, skinless\u001b[0m\n","\u001b[32mchicken breasts · ½ cup plain yogurt · 2 tablespoons lemon juice · 6 cloves garlic, minced · 1 tablespoon minced \u001b[0m\n","\u001b[32m... Missing: steps instructions. We start by marinating the chicken in a mixture of yogurt and spices. It needs to \u001b[0m\n","\u001b[32mmarinade for at least a couple of hours, to really tenderize ... Step-by-Step Instructions ... Begin by chopping \u001b[0m\n","\u001b[32mthe chicken breasts into chunks. Feel free to substitute boneless skinless chicken thighs if you ... Missing: steps\u001b[0m\n","\u001b[32m| Show results with:steps. A made-from-scratch Chicken Tikka Masala recipe with the signature yoghurt marinated \u001b[0m\n","\u001b[32mchargrilled chicken smothered in an incredible spice ... ... chicken tikka masala then this recipe is the right \u001b[0m\n","\u001b[32mchoice for you. Today I will show you step ... Duration: 9:35. Posted: Jul 24, 2020.'\u001b[0m\n","\u001b[1m}\u001b[0m\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">AIMessage</span><span style=\"font-weight: bold\">(</span>\n","    <span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'## Chicken Tikka Masala Recipe &amp; Instructions:\\n\\nWhile a complete, unified recipe is not available in</span>\n","<span style=\"color: #008000; text-decoration-color: #008000\">the provided search results, we can piece together a coherent recipe and instructions by combining the most </span>\n","<span style=\"color: #008000; text-decoration-color: #008000\">relevant information:\\n\\n**Ingredients:**\\n\\n* **For the Chicken Marinade:**\\n    * 1 ½ pounds boneless skinless </span>\n","<span style=\"color: #008000; text-decoration-color: #008000\">chicken thighs (or breasts), cut into 1-inch chunks\\n    * 1 cup plain yogurt\\n    * 1 tablespoon lemon juice\\n    </span>\n","<span style=\"color: #008000; text-decoration-color: #008000\">* 4 teaspoons ground cumin (divided)\\n    * 1 teaspoon ground cinnamon\\n    * 2 teaspoons cayenne pepper\\n    * 6 </span>\n","<span style=\"color: #008000; text-decoration-color: #008000\">cloves garlic, minced\\n    * 1 tablespoon minced ginger\\n    * Kosher salt and freshly ground black pepper to </span>\n","<span style=\"color: #008000; text-decoration-color: #008000\">taste\\n* **For the Sauce:**\\n    * 1 cup basmati rice (for serving)\\n    * Butter \\n    * 1 large onion, chopped\\n </span>\n","<span style=\"color: #008000; text-decoration-color: #008000\">* Additional garlic cloves \\n    * Ground cumin\\n    * Paprika\\n    * Garam masala\\n    * Chili powder\\n    * </span>\n","<span style=\"color: #008000; text-decoration-color: #008000\">Salt\\n    * Tomato sauce\\n    * Heavy cream\\n    * Honey\\n\\n**Instructions:**\\n\\n1. **Marinate the Chicken:** In a </span>\n","<span style=\"color: #008000; text-decoration-color: #008000\">large bowl, combine all the chicken marinade ingredients. Ensure the chicken is well coated. Cover and refrigerate </span>\n","<span style=\"color: #008000; text-decoration-color: #008000\">for at least 3 hours, preferably overnight.\\n2. **Cook the Chicken Tikka:**\\n    * **Oven Method:** Thread </span>\n","<span style=\"color: #008000; text-decoration-color: #008000\">marinated chicken onto skewers. Place on a baking tray and bake in a preheated oven at 460°F (240°C) for 9-10 </span>\n","<span style=\"color: #008000; text-decoration-color: #008000\">minutes per side, or until cooked through.\\n    * **Other Methods:** You can also grill, air fry, or use an Instant</span>\n","<span style=\"color: #008000; text-decoration-color: #008000\">Pot to cook the chicken tikka. Adjust cooking times accordingly.\\n3. **Prepare the Sauce:** While the chicken </span>\n","<span style=\"color: #008000; text-decoration-color: #008000\">cooks, melt butter in a large skillet or dutch oven over medium heat. Sauté onions until softened, then add garlic </span>\n","<span style=\"color: #008000; text-decoration-color: #008000\">and cook for another minute.\\n4. **Bloom the Spices:**  Add cumin, paprika, garam masala, chili powder, and salt to</span>\n","<span style=\"color: #008000; text-decoration-color: #008000\">the pan. Stir and cook for a minute to release their flavors.\\n5. **Simmer the Sauce:** Stir in tomato sauce and </span>\n","<span style=\"color: #008000; text-decoration-color: #008000\">cream. Reduce heat to medium-low and simmer for about 20 minutes, stirring occasionally, until the sauce </span>\n","<span style=\"color: #008000; text-decoration-color: #008000\">thickens.\\n6. **Combine and Finish:** Add the cooked chicken tikka to the sauce and simmer for 5 more minutes. Stir</span>\n","<span style=\"color: #008000; text-decoration-color: #008000\">in honey and heavy whipping cream. Adjust seasoning as needed. \\n7. **Serve:** Serve the chicken tikka masala hot </span>\n","<span style=\"color: #008000; text-decoration-color: #008000\">with basmati rice. \\n\\n\\n**Note:** This recipe is a compilation from various sources.  You may need to adjust the </span>\n","<span style=\"color: #008000; text-decoration-color: #008000\">ingredient quantities and cooking times to your preference. \\n'</span>,\n","    <span style=\"color: #808000; text-decoration-color: #808000\">response_metadata</span>=<span style=\"font-weight: bold\">{</span>\n","        <span style=\"color: #008000; text-decoration-color: #008000\">'prompt_feedback'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'block_reason'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'safety_ratings'</span>: <span style=\"font-weight: bold\">[]}</span>,\n","        <span style=\"color: #008000; text-decoration-color: #008000\">'finish_reason'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'STOP'</span>,\n","        <span style=\"color: #008000; text-decoration-color: #008000\">'safety_ratings'</span>: <span style=\"font-weight: bold\">[</span>\n","            <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'category'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'HARM_CATEGORY_SEXUALLY_EXPLICIT'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'probability'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'NEGLIGIBLE'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'blocked'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">}</span>,\n","            <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'category'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'HARM_CATEGORY_HATE_SPEECH'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'probability'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'NEGLIGIBLE'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'blocked'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">}</span>,\n","            <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'category'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'HARM_CATEGORY_HARASSMENT'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'probability'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'NEGLIGIBLE'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'blocked'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">}</span>,\n","            <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'category'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'HARM_CATEGORY_DANGEROUS_CONTENT'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'probability'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'NEGLIGIBLE'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'blocked'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">}</span>\n","        <span style=\"font-weight: bold\">]</span>\n","    <span style=\"font-weight: bold\">}</span>,\n","    <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'run-ec92a09e-5c9c-41b7-9191-d1032e078e6e-0'</span>,\n","    <span style=\"color: #808000; text-decoration-color: #808000\">usage_metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'input_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">842</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'output_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">574</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'total_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1416</span><span style=\"font-weight: bold\">}</span>\n","<span style=\"font-weight: bold\">)</span>\n","</pre>\n"],"text/plain":["\u001b[1;35mAIMessage\u001b[0m\u001b[1m(\u001b[0m\n","    \u001b[33mcontent\u001b[0m=\u001b[32m'## Chicken Tikka Masala Recipe & Instructions:\\n\\nWhile a complete, unified recipe is not available in\u001b[0m\n","\u001b[32mthe provided search results, we can piece together a coherent recipe and instructions by combining the most \u001b[0m\n","\u001b[32mrelevant information:\\n\\n**Ingredients:**\\n\\n* **For the Chicken Marinade:**\\n    * 1 ½ pounds boneless skinless \u001b[0m\n","\u001b[32mchicken thighs \u001b[0m\u001b[32m(\u001b[0m\u001b[32mor breasts\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, cut into 1-inch chunks\\n    * 1 cup plain yogurt\\n    * 1 tablespoon lemon juice\\n    \u001b[0m\n","\u001b[32m* 4 teaspoons ground cumin \u001b[0m\u001b[32m(\u001b[0m\u001b[32mdivided\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n    * 1 teaspoon ground cinnamon\\n    * 2 teaspoons cayenne pepper\\n    * 6 \u001b[0m\n","\u001b[32mcloves garlic, minced\\n    * 1 tablespoon minced ginger\\n    * Kosher salt and freshly ground black pepper to \u001b[0m\n","\u001b[32mtaste\\n* **For the Sauce:**\\n    * 1 cup basmati rice \u001b[0m\u001b[32m(\u001b[0m\u001b[32mfor serving\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n    * Butter \\n    * 1 large onion, chopped\\n \u001b[0m\n","\u001b[32m* Additional garlic cloves \\n    * Ground cumin\\n    * Paprika\\n    * Garam masala\\n    * Chili powder\\n    * \u001b[0m\n","\u001b[32mSalt\\n    * Tomato sauce\\n    * Heavy cream\\n    * Honey\\n\\n**Instructions:**\\n\\n1. **Marinate the Chicken:** In a \u001b[0m\n","\u001b[32mlarge bowl, combine all the chicken marinade ingredients. Ensure the chicken is well coated. Cover and refrigerate \u001b[0m\n","\u001b[32mfor at least 3 hours, preferably overnight.\\n2. **Cook the Chicken Tikka:**\\n    * **Oven Method:** Thread \u001b[0m\n","\u001b[32mmarinated chicken onto skewers. Place on a baking tray and bake in a preheated oven at 460°F \u001b[0m\u001b[32m(\u001b[0m\u001b[32m240°C\u001b[0m\u001b[32m)\u001b[0m\u001b[32m for 9-10 \u001b[0m\n","\u001b[32mminutes per side, or until cooked through.\\n    * **Other Methods:** You can also grill, air fry, or use an Instant\u001b[0m\n","\u001b[32mPot to cook the chicken tikka. Adjust cooking times accordingly.\\n3. **Prepare the Sauce:** While the chicken \u001b[0m\n","\u001b[32mcooks, melt butter in a large skillet or dutch oven over medium heat. Sauté onions until softened, then add garlic \u001b[0m\n","\u001b[32mand cook for another minute.\\n4. **Bloom the Spices:**  Add cumin, paprika, garam masala, chili powder, and salt to\u001b[0m\n","\u001b[32mthe pan. Stir and cook for a minute to release their flavors.\\n5. **Simmer the Sauce:** Stir in tomato sauce and \u001b[0m\n","\u001b[32mcream. Reduce heat to medium-low and simmer for about 20 minutes, stirring occasionally, until the sauce \u001b[0m\n","\u001b[32mthickens.\\n6. **Combine and Finish:** Add the cooked chicken tikka to the sauce and simmer for 5 more minutes. Stir\u001b[0m\n","\u001b[32min honey and heavy whipping cream. Adjust seasoning as needed. \\n7. **Serve:** Serve the chicken tikka masala hot \u001b[0m\n","\u001b[32mwith basmati rice. \\n\\n\\n**Note:** This recipe is a compilation from various sources.  You may need to adjust the \u001b[0m\n","\u001b[32mingredient quantities and cooking times to your preference. \\n'\u001b[0m,\n","    \u001b[33mresponse_metadata\u001b[0m=\u001b[1m{\u001b[0m\n","        \u001b[32m'prompt_feedback'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'block_reason'\u001b[0m: \u001b[1;36m0\u001b[0m, \u001b[32m'safety_ratings'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\u001b[1m}\u001b[0m,\n","        \u001b[32m'finish_reason'\u001b[0m: \u001b[32m'STOP'\u001b[0m,\n","        \u001b[32m'safety_ratings'\u001b[0m: \u001b[1m[\u001b[0m\n","            \u001b[1m{\u001b[0m\u001b[32m'category'\u001b[0m: \u001b[32m'HARM_CATEGORY_SEXUALLY_EXPLICIT'\u001b[0m, \u001b[32m'probability'\u001b[0m: \u001b[32m'NEGLIGIBLE'\u001b[0m, \u001b[32m'blocked'\u001b[0m: \u001b[3;91mFalse\u001b[0m\u001b[1m}\u001b[0m,\n","            \u001b[1m{\u001b[0m\u001b[32m'category'\u001b[0m: \u001b[32m'HARM_CATEGORY_HATE_SPEECH'\u001b[0m, \u001b[32m'probability'\u001b[0m: \u001b[32m'NEGLIGIBLE'\u001b[0m, \u001b[32m'blocked'\u001b[0m: \u001b[3;91mFalse\u001b[0m\u001b[1m}\u001b[0m,\n","            \u001b[1m{\u001b[0m\u001b[32m'category'\u001b[0m: \u001b[32m'HARM_CATEGORY_HARASSMENT'\u001b[0m, \u001b[32m'probability'\u001b[0m: \u001b[32m'NEGLIGIBLE'\u001b[0m, \u001b[32m'blocked'\u001b[0m: \u001b[3;91mFalse\u001b[0m\u001b[1m}\u001b[0m,\n","            \u001b[1m{\u001b[0m\u001b[32m'category'\u001b[0m: \u001b[32m'HARM_CATEGORY_DANGEROUS_CONTENT'\u001b[0m, \u001b[32m'probability'\u001b[0m: \u001b[32m'NEGLIGIBLE'\u001b[0m, \u001b[32m'blocked'\u001b[0m: \u001b[3;91mFalse\u001b[0m\u001b[1m}\u001b[0m\n","        \u001b[1m]\u001b[0m\n","    \u001b[1m}\u001b[0m,\n","    \u001b[33mid\u001b[0m=\u001b[32m'run-ec92a09e-5c9c-41b7-9191-d1032e078e6e-0'\u001b[0m,\n","    \u001b[33musage_metadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'input_tokens'\u001b[0m: \u001b[1;36m842\u001b[0m, \u001b[32m'output_tokens'\u001b[0m: \u001b[1;36m574\u001b[0m, \u001b[32m'total_tokens'\u001b[0m: \u001b[1;36m1416\u001b[0m\u001b[1m}\u001b[0m\n","\u001b[1m)\u001b[0m\n"]},"metadata":{},"output_type":"display_data"}],"source":["from langchain_community.utilities import DuckDuckGoSearchAPIWrapper, WikipediaAPIWrapper, GoogleSerperAPIWrapper\n","from langchain_core.runnables import RunnableParallel, RunnableMap\n","from dotenv import load_dotenv\n","# from langchain_openai import ChatOpenAI  # Assuming you want to use this for summarization\n","from rich import print\n","load_dotenv() \n","\n","# Initialize search wrappers for each search engine\n","duckduckgo_search = DuckDuckGoSearchAPIWrapper()\n","wikipedia_search = WikipediaAPIWrapper()\n","serperapi_search = GoogleSerperAPIWrapper()\n","\n","# Create a parallel runnable for the searches\n","search_chain = RunnableParallel(\n","    duckduckgo=duckduckgo_search.run,\n","    wikipedia=wikipedia_search.run,\n","    serperapi=serperapi_search.run,\n",")\n","\n","# Initialize the model for summarization\n","summarization_model = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\")\n","\n","# Define a function to summarize the results\n","def summarize_results(results, query):\n","    print(results)\n","    prompt = f\"\"\"\n","    You have received the following search results for the query: {query}\n","\n","    DuckDuckGo: {results['duckduckgo']}\n","    Wikipedia: {results['wikipedia']}\n","    Google Serper: {results['serperapi']}\n","\n","    Your Job is to provide only the most accurate information from these results for the given query.\n","    \"\"\"\n","    summary = summarization_model.invoke(prompt)\n","    return summary\n","\n","query = \"Giive me the Recipe for Chicken Tikka Masala and also the steps by step instructions\"\n","first_chain_result = search_chain.invoke(query)\n","second_chain_result = summarize_results(first_chain_result, query)\n","print(second_chain_result)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from langchain_community.utilities import DuckDuckGoSearchAPIWrapper, WikipediaAPIWrapper, GoogleSerperAPIWrapper\n","from langchain_core.runnables import RunnableParallel, RunnableMap\n","from dotenv import load_dotenv\n","# from langchain_openai import ChatOpenAI  # Assuming you want to use this for summarization\n","from rich import print\n","load_dotenv() \n","\n","# Initialize search wrappers for each search engine\n","duckduckgo_search = DuckDuckGoSearchAPIWrapper()\n","wikipedia_search = WikipediaAPIWrapper()\n","serperapi_search = GoogleSerperAPIWrapper()\n","\n","# Create a parallel runnable for the searches\n","search_chain = RunnableParallel(\n","    duckduckgo=duckduckgo_search.run,\n","    wikipedia=wikipedia_search.run,\n","    serperapi=serperapi_search.run,\n",")\n","\n","# Initialize the model for summarization\n","summarization_model = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\")\n","\n","# Define a function to summarize the results\n","def summarize_results(results, query):\n","    print(results)\n","    prompt = f\"\"\"\n","    You have received the following search results for the query: {query}\n","\n","    DuckDuckGo: {results['duckduckgo']}\n","    Wikipedia: {results['wikipedia']}\n","    Google Serper: {results['serperapi']}\n","\n","    Your Job is to provide only the most accurate information from these results for the given query.\n","    \"\"\"\n","    summary = summarization_model.invoke(prompt)\n","    return summary\n","\n","query = \"What are the Harmful effects of Smoking\"\n","first_chain_result = search_chain.invoke(query)\n","\n","\n","second_chain_result = summarize_results(first_chain_result, query)\n","print(second_chain_result)"]},{"cell_type":"markdown","metadata":{},"source":["## Agent"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\Nilay Kumar\\Desktop\\langchain_app\\venv\\Lib\\site-packages\\langchain\\hub.py:86: DeprecationWarning: The `langchainhub sdk` is deprecated.\n","Please use the `langsmith sdk` instead:\n","  pip install langsmith\n","Use the `pull_prompt` method.\n","  res_dict = client.pull_repo(owner_repo_commit)\n"]},{"name":"stdout","output_type":"stream","text":["\n","\n","\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"]},{"name":"stderr","output_type":"stream","text":["Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[32;1m\u001b[1;3mThought: I need to search for the gold medal count of the 2024 Olympics. \n","Action: tavily_search_results_json\n","Action Input: 2024 Olympics gold medal count \u001b[0m\u001b[36;1m\u001b[1;3m[{'url': 'https://www.sportingnews.com/uk/olympics/news/olympics-winner-2024-final-medal-standings-usa/10d8066d05bb7d20c197104f', 'content': \"SN's 2024 OLYMPICS HQ Updated medal count ... Here's a look at the 10 countries with the most gold medals at the Paris Olympics: Country: Gold medals: Overall medals: USA: 40: 126: China: 40: 91 ...\"}, {'url': 'https://www.sportingnews.com/us/olympics/news/usa-medal-count-2024-olympics-gold-silver-bronze/8311c9b2059e5d6257b1d81c', 'content': 'The Sporting News is tracking of all Olympic medals won by the United States at the 2024 Paris Olympics. USA medal count 2024: Updated tracker of Olympic gold, silver, bronze medals for United ...'}, {'url': 'https://www.bbc.co.uk/sport/olympics/paris-2024/medals', 'content': 'Find out the medal table from the Paris Olympics 2024, including overall medals, gold medals, silver medals and bronze medals for Team GB and other countries.'}, {'url': 'https://www.npr.org/2024/08/11/nx-s1-5071150/paris-olympics-medal-total-us-gold', 'content': \"Katie Ledecky scored two of America's forty Olympic gold medals in the Paris Summer Games. The U.S. tied with China for the most gold, but the U.S. dominated the overall count with 126 medals ...\"}, {'url': 'https://www.sportingnews.com/us/olympics/news/olympics-medal-count-2024-standings/d71c97e2053626649fad6312', 'content': 'See which countries are leading the medal count at the 2024 Paris Olympics, with the United States and China in a tight race for the top spot. Follow along for the latest updates, schedules, and highlights of the Summer Games.'}]\u001b[0m\u001b[32;1m\u001b[1;3mThought: The USA and China tied for the most gold medals.\n","Final Answer: The USA and China tied for the most gold medals at the 2024 Olympics. \n","\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"data":{"text/plain":["{'input': 'Who won the most golds in 2024 olympics?',\n"," 'chat_history': [HumanMessage(content='Who won the most golds in 2024 olympics?'),\n","  AIMessage(content='The USA and China tied for the most gold medals at the 2024 Olympics.')],\n"," 'output': 'The USA and China tied for the most gold medals at the 2024 Olympics.'}"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["from langchain.prompts import PromptTemplate \n","from langchain.agents import initialize_agent                                   \n","from langchain.memory import ConversationBufferMemory\n","from langchain.agents import AgentType\n","from langchain_google_genai import ChatGoogleGenerativeAI\n","from langchain_community.tools.tavily_search import TavilySearchResults\n","from dotenv import load_dotenv\n","from langchain.agents.agent import AgentExecutor\n","from langchain.agents import initialize_agent, create_react_agent\n","from langchain import hub\n","\n","#  AgentExecutor.from_agent_and_tools\n","load_dotenv()\n","llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\")\n","search = TavilySearchResults()\n","tools = [search]\n","memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n","\n","prompt = hub.pull(\"hwchase17/react\")\n","\n","agent = create_react_agent(\n","    llm=llm,\n","    tools=tools,\n","    prompt=prompt,\n",")\n","\n","agent_executor = AgentExecutor.from_agent_and_tools(\n","    agent=agent,\n","    tools=tools,\n","    llm=llm,\n","    max_iterations=4,\n","    verbose=True,\n","    memory=memory,\n","    handle_parsing_errors=True,\n","    return_intermediate_steps=False,\n","    # agent_kwargs={\n","        # 'prefix': PREFIX, \n","    #     'format_instructions': FORMAT_INSTRUCTIONS,\n","    #     'suffix': SUFFIX\n","    # }\n",")\n","\n","agent_executor.invoke({\"input\": \"Who won the most golds in 2024 olympics?\"})\n","# while True:\n","#     query = input(\"Query: \")\n","#     if query == \"exit\":\n","#         break\n","#     print(\"User: \", query)\n","#     response = agent.invoke({\"input\": query})\n","#     print(\"AI: \", response.get(\"output\"))"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["from langchain.agents import Tool\n","from langchain.chains import RetrievalQA\n","from langchain_community.vectorstores import FAISS\n","\n","uploader = ScanDocuments()\n","data = uploader.upload_single_file(\"files/2205.15868v1-CogVideo-Large-scale Pretraining for Text-to-Video.pdf\")\n","documents = uploader.process_document(data)\n","\n","\n","embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n","llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\")\n","model = Model(llm, embeddings)\n","\n","vector_store = VectorStore(model, search_num_docs=10)\n","vector_store.add_documents(documents)\n","\n","vectordb_search_tool =Tool(\n","        name = \"Vector Database Search Tool\",\n","        func=vector_store.qa_chain.invoke,\n","        description=\"\"\"Useful for when you want to search information regarding a document uploaded by the User. \n","        If the User Query seems vague try to search for the same in vector Store and ask The user if the Query is regarding the paper in the Vector Store?\n","        \"\"\"\n","    )\n","\n","# vectordb_search_tool.invoke(\"What is the main idea of the paper? WHat are the math formulas used in this paper\")"]},{"cell_type":"code","execution_count":59,"metadata":{},"outputs":[{"data":{"text/plain":["<langchain_community.vectorstores.faiss.FAISS at 0x17a7b2b6ff0>"]},"execution_count":59,"metadata":{},"output_type":"execute_result"}],"source":["\n","# FAISS."]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\Nilay Kumar\\Desktop\\langchain_app\\venv\\Lib\\site-packages\\langchain\\hub.py:86: DeprecationWarning: The `langchainhub sdk` is deprecated.\n","Please use the `langsmith sdk` instead:\n","  pip install langsmith\n","Use the `pull_prompt` method.\n","  res_dict = client.pull_repo(owner_repo_commit)\n"]},{"name":"stdout","output_type":"stream","text":["\n","\n","\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n","\u001b[32;1m\u001b[1;3mThought: The question is asking for an explanation of a research paper. This is likely best answered from a vector database of research papers.\n","Action: Vector Database Search Tool\n","Action Input: {\"query\": \"Explain in Detail The idea behind the paper CogVideo\"}\u001b[0m\u001b[33;1m\u001b[1;3m{'query': '{\"query\": \"Explain in Detail The idea behind the paper CogVideo\"}', 'result': \"CogVideo aims to tackle the challenging task of **text-to-video generation**, essentially teaching machines to create videos from text descriptions.  Here's a breakdown of its key ideas:\\n\\n**1. Building on Existing Knowledge:**\\n\\n* Instead of starting from scratch, CogVideo leverages the power of a pre-trained text-to-image model called CogView2. This allows it to inherit a strong understanding of visual concepts and their relationship to language.\\n\\n**2. Multi-Frame-Rate Hierarchical Training:**\\n\\n* Videos involve motion, which is challenging to capture from text alone. CogVideo addresses this by using a hierarchical approach with varying frame rates:\\n    * **Stage 1: Sequential Generation:** The model generates key frames sequentially based on the text prompt and a specified frame rate. This frame rate (e.g., 1 fps, 4 fps) is embedded within the input, providing control over the speed and granularity of the generated action.\\n    * **Stage 2: Recursive Interpolation:** The generated keyframes are then used as anchor points. The model recursively fills in the gaps by interpolating intermediate frames at different frame rates. This creates smoother and more coherent motion.\\n\\n**3. Efficient Fine-tuning:**\\n\\n* CogVideo doesn't require training from scratch.  It efficiently fine-tunes the pre-trained CogView2 model by:\\n    * Fixing a significant portion of CogView2's parameters, reducing training time and memory requirements.\\n    * Introducing a dual-channel attention mechanism, where one channel focuses on spatial information (inherited from CogView2) and the other handles temporal dynamics specific to video.\\n\\n**4. Large-Scale Training Data:**\\n\\n* CogVideo is trained on a massive dataset of 5.4 million text-video pairs. This vast amount of data helps the model learn complex relationships between language and dynamic visual content.\\n\\n**In essence, CogVideo combines the efficiency of transfer learning from a powerful text-to-image model with a novel hierarchical training strategy that explicitly handles temporal dynamics. This enables it to generate high-resolution videos from text descriptions, pushing the boundaries of AI-powered video creation.** \\n\", 'source_documents': [Document(metadata={'source': 'files/2205.15868v1-CogVideo-Large-scale Pretraining for Text-to-Video.pdf', 'page': 11}, page_content='perspective with Figure 9, which shows that features calculated by CogView2 in the spatial channel\\nare heavily relied on.\\nB Training Details\\nCogVideo consists of two models corresponding to two stages, i.e. sequential generation and recursive\\ninterpolation. Both models have 7.7 billion parameters while 6 billion of them are ﬁxed to CogView2,\\nthus CogVideo has 9.4 billion different parameters in total.\\nCogVideo is trained on a dataset of 5.4 million captioned videos with a spatial resolution of 160 ×160\\n(can be upsampled to 480 ×480 by CogView2). Each model is pretrained separately. The model in\\nstage 1 is ﬁrst pretrained for 76,000 iterations on video clips with a minimum frame rate of 0.25\\nfps, then trained for 15,000 iterations with a minimum frame rate of 1 fps. The model in stage 2 is\\npretrained for 78,500 iterations with the frame rate of 2, 4, and 8 fps. Both models are trained in\\nFP16 with a batch size of 416, and optimized by Adam with max learning rate = 2×10−4,β1= 0.9,'), Document(metadata={'source': 'files/2205.15868v1-CogVideo-Large-scale Pretraining for Text-to-Video.pdf', 'page': 1}, page_content='text-to-image generation, avoiding the expensive full pretraining from scratch.\\n•We propose the multi-frame-rate hierarchical training to better align text-clip pairs, which\\nsigniﬁcantly improves the generation accuracy, in particular for movements of complex\\nsemantics. This training strategy endows CogVideo with the capacity of controlling the\\nintensity of changes during the generation.\\n2 Related Work\\n2.1 Video Generation\\nVideo generation is a long-standing research topic. Most previous works focus on the next-frame\\nprediction task — forecasting the future frames based on the ﬁrst video frame. Early works, e.g.\\n2'), Document(metadata={'source': 'files/2205.15868v1-CogVideo-Large-scale Pretraining for Text-to-Video.pdf', 'page': 6}, page_content='et al. [17], we center-crop and downsample each frame to 64 ×64 to measure the FVD of the model.\\nResults are shown in Table 1 (Right).\\n5.2 Human Evaluation\\nTo further evaluate CogVideo, we invite 90 anonymous evaluators to rate for CogVideo and other open-\\nsource baselines including GAN-based model TGANv2 [ 20] and GPT-based model VideoGPT [ 36].\\n30 classes in UCF101 are randomly picked as text conditions, and several aspects are rated (See\\nAppendix for details). For VideoGPT, we use the ofﬁcial unconditional pretrained model4to generate\\nsamples. For TGANv2, we use the ofﬁcial source code to train an unconditional generation model\\nunder the same setting as that in Saito et al. [20]. To assign unconditionally generated samples\\ninto corresponding categories, we choose TSM [ 13] as the action recognition model for a post-\\nclassiﬁcation. We only keep the samples whose likelihood to a certain class is at least 80%. Results'), Document(metadata={'source': 'files/2205.15868v1-CogVideo-Large-scale Pretraining for Text-to-Video.pdf', 'page': 3}, page_content='<latexit sha1_base64=\"WkmkOQqV4y/G2CwEGjey+GFekFc=\">AAACAnicbVDLSgMxFM3UV62vUVfiJlgEV2VGi7osuHFZwT6gM5RMeqcNzWSGJCOUobjxV9y4UMStX+HOvzHTzkJbD4Qczrn3JvcECWdKO863VVpZXVvfKG9WtrZ3dvfs/YO2ilNJoUVjHstuQBRwJqClmebQTSSQKODQCcY3ud95AKlYLO71JAE/IkPBQkaJNlLfPvJiYweSUMi8kUry+9JJ9HTat6tOzZkBLxO3IFVUoNm3v7xBTNMIhKacKNVzzRw/I1IzymFa8VIFZv6YDKFnqCARKD+brTDFp0YZ4DCW5giNZ+rvjoxESk2iwFRGRI/UopeL/3m9VIfXfsZEkmoQdP5QmHKsY5zngQdMAtV8Ygihkpm/YjoiJg9tUquYENzFlZdJ+7zmXtScu3q1US/iKKNjdILOkIuuUAPdoiZqIYoe0TN6RW/Wk/VivVsf89KSVfQcoj+wPn8A712XuA==</latexit>\\nInterpolateframesInput Frames:Figure 2: Multi-frame-rate hierarchical generation framework in CogVideo. Input sequence includes\\nframe rate, text, frame tokens. [B] (Begin-of-image) is a separator token, inherited from CogView2.\\nIn stage 1,Tsframes are generated sequentially on condition of frame rate and text. Then in stage\\n2, generated frames are re-input as bidirectional attention regions to recursively interpolate frames.'), Document(metadata={'source': 'files/2205.15868v1-CogVideo-Large-scale Pretraining for Text-to-Video.pdf', 'page': 1}, page_content='also controls the intensity of the changes throughout continuous frames in generation. Speciﬁcally,\\nwe train a sequential generation model and a frame interpolation model. The former model generates\\nkey frames according to the text, and the latter recursively ﬁll the middle frames by varying the frame\\nrates to make the video coherent. As shown in Figure 1, CogVideo can generate high-resolution\\n(480×480) videos. Human evaluation demonstrates that CogVideo outperforms all publicly available\\nmodels at a large margin. Our main contributions can be concluded as follows:\\n•We present CogVideo, which is the largest andthe ﬁrst open-source pretrained transformer\\nfor text-to-video generation in the general domain.\\n•CogVideo elegantly and efﬁciently ﬁnetunes a pretrained text-to-image generative model for\\ntext-to-image generation, avoiding the expensive full pretraining from scratch.\\n•We propose the multi-frame-rate hierarchical training to better align text-clip pairs, which'), Document(metadata={'source': 'files/2205.15868v1-CogVideo-Large-scale Pretraining for Text-to-Video.pdf', 'page': 8}, page_content='(c) Randomly Initialized\\n(d) Finetuned CogVideo, 1-Stage\\n(e) Finetuned CogVideo, 1-Stage(b) Initialized with CogView2 (a) Finetuned CogVideo, hierarchical generation\\nInput Text: LungeGiven frames:\\nFigure 7: Video samples in ablation study, which are generated priming on the class label and ﬁrst 5\\nframes in Kinetics-600. All samples are downsampled by extracting one in every three frames for\\ndisplay purposes. (a) Use ﬁnetuned CogVideo to hierarchically generate samples. (b) Train a model\\non Kinetics-600 which is initialized as and partially ﬁxed to CogView2, and hierarchically generate\\nsamples. (c) Train a model on Kinetics-600 which is randomly initialized, and hierarchically generate\\nsamples. (d)(e) Use ﬁnetuned CogVideo to generate frames in 1 stage with different Noverlap .\\na good initialization point from which the loss can decrease faster. Moreover, ﬁxing part of the\\nparameters reduces the time and memory cost.\\n5.3.2 Qualitative Evaluation'), Document(metadata={'source': 'files/2205.15868v1-CogVideo-Large-scale Pretraining for Text-to-Video.pdf', 'page': 7}, page_content='during the inference, but will increase time overhead.\\nDual-channel attention with CogView2’s weights. To highlight the effectiveness of our ﬁnetuning\\nstrategy, we additionally ﬁnetune (1) a randomly initialized model, (2) a model incorporating\\nCogView2’s weights but leaving the temporal channel unﬁxed (equivalent to CogVideo without\\npretraining on videos) on Kinetics-600 for comparison.\\n5.3.1 Quantitative Evaluation\\nFigure 6: Training loss in ablation study.All aforementioned models have been trained for 11,000\\niterations with a batch size of 160. Quantitative results are\\nshown in Table 2. We can see that the hierarchical method\\nis clearly superior to the 1-stage generation with differ-\\nentNoverlap , and the model initialized with CogView2’s\\nweights has lower FVD than the randomly initialized one.\\nFigure 6 plots the training loss curve of (1) ﬁnetuning\\nCogVideo; (2) training model from random initialization;\\n(3) training model initialized with CogView2 and partially'), Document(metadata={'source': 'files/2205.15868v1-CogVideo-Large-scale Pretraining for Text-to-Video.pdf', 'page': 1}, page_content='which is of 9.4 billion parameters and trained on 5.4 million text-video pairs. We build CogVideo\\nbased on a pretrained text-to-image model, CogView2 [ 6], in order to inherit the knowledge learned\\nfrom the text-image pretraining. To ensure the alignment between text and its temporal counterparts\\nin the video, we propose the multi-frame-rate hierarchical training . The ﬂexibility of the textual\\ncondition makes it possible to simply prepend a piece of text describing the frame rate to the original\\ntext prompt for modeling different frame rates. To keep the text-video alignment, we choose a proper\\nframe rate description to include the complete action in each training sample. The frame rate token\\nalso controls the intensity of the changes throughout continuous frames in generation. Speciﬁcally,\\nwe train a sequential generation model and a frame interpolation model. The former model generates'), Document(metadata={'source': 'files/2205.15868v1-CogVideo-Large-scale Pretraining for Text-to-Video.pdf', 'page': 1}, page_content='41,250 videos. The retrieval-based text-video pairs, e.g. Howto100M [ 16], are weakly relevant and\\nmost of them only describe the scene without the temporal information.\\nSecond, the duration of videos varies a lot. Previous models split the video into many clips of a\\nﬁxed number of frames for training, which destroys the alignment between the text and its temporal\\ncounterparts in the video. If a “drinking” video is split into four individual clips of “holding a glass”,\\n“lifting”, “drinking” and “putting down” with the same text “drinking”, the model will be confused to\\nlearn the accurate meaning of drinking.\\nPresent Work. Here we present a large-scale pretrained text-to-video generative model, CogVideo,\\nwhich is of 9.4 billion parameters and trained on 5.4 million text-video pairs. We build CogVideo\\nbased on a pretrained text-to-image model, CogView2 [ 6], in order to inherit the knowledge learned'), Document(metadata={'source': 'files/2205.15868v1-CogVideo-Large-scale Pretraining for Text-to-Video.pdf', 'page': 6}, page_content='CogVideo (Ours) 109.23\\nCogVideo (Ours)** 59.55\\n5 Experiments\\n5.1 Machine Evaluation\\nMachine evaluation is conducted on two popular benchmarks for video generation, i.e., UCF101 [ 22]\\nand Kinetics-600 [ 3]. Following Rakhimov et al. [17], Yu et al. [37], we use Fréchet Video Distance\\n(FVD) [ 27] and Inception score (IS) [ 21] as metrics in the evaluation. FVD is calculated based on\\nI3D model[ 2] trained on Kinetics-400, and IS is based on C3D model [ 25] which was ﬁrst trained on\\nthe Sports-1M dataset [ 12] and then ﬁnetuned on the UCF101 dataset. Our evaluation code is the\\nsame as the ofﬁcial TGAN-v2 implementation3.\\nUCF-101 is a human action dataset consisting of 13,320 videos annotated with 101 action classes.\\nDue to the gaps of image style and frame rate between CogVideo’s training set and UCF-101, we use\\nclass labels as the input text and ﬁnetune CogVideo on the whole dataset for 10,000 iterations with a')]}\u001b[0m\u001b[32;1m\u001b[1;3mThought: The vector database was able to find an explanation of the CogVideo paper.\n","Final Answer: CogVideo is a text-to-video generation model that builds on the pre-trained text-to-image model CogView2. It uses a multi-frame-rate hierarchical training approach to generate videos from text descriptions. The model first generates keyframes sequentially based on the text prompt and a specified frame rate. Then, it recursively interpolates intermediate frames at different frame rates to create smoother and more coherent motion. CogVideo is trained on a massive dataset of 5.4 million text-video pairs, which helps it learn complex relationships between language and dynamic visual content. \n","\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"data":{"text/plain":["{'input': 'Can you Explain in Detail The idea behind the paper CogVideo',\n"," 'chat_history': [HumanMessage(content='Can you Explain in Detail The idea behind the paper CogVideo'),\n","  AIMessage(content='CogVideo is a text-to-video generation model that builds on the pre-trained text-to-image model CogView2. It uses a multi-frame-rate hierarchical training approach to generate videos from text descriptions. The model first generates keyframes sequentially based on the text prompt and a specified frame rate. Then, it recursively interpolates intermediate frames at different frame rates to create smoother and more coherent motion. CogVideo is trained on a massive dataset of 5.4 million text-video pairs, which helps it learn complex relationships between language and dynamic visual content.')],\n"," 'output': 'CogVideo is a text-to-video generation model that builds on the pre-trained text-to-image model CogView2. It uses a multi-frame-rate hierarchical training approach to generate videos from text descriptions. The model first generates keyframes sequentially based on the text prompt and a specified frame rate. Then, it recursively interpolates intermediate frames at different frame rates to create smoother and more coherent motion. CogVideo is trained on a massive dataset of 5.4 million text-video pairs, which helps it learn complex relationships between language and dynamic visual content.'}"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["search_engine_tool = TavilySearchResults()\n","\n","tools = [search_engine_tool, vectordb_search_tool]\n","\n","memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n","prompt = hub.pull(\"hwchase17/react\")\n","\n","agent = create_react_agent(\n","    llm=llm,\n","    tools=tools,\n","    prompt=prompt,\n",")\n","\n","agent_executor = AgentExecutor.from_agent_and_tools(\n","    agent=agent,\n","    tools=tools,\n","    llm=llm,\n","    max_iterations=15,\n","    verbose=True,\n","    memory=memory,\n","    handle_parsing_errors=True,\n","    return_intermediate_steps=False,\n","    # agent_kwargs={\n","        # 'prefix': PREFIX, \n","    #     'format_instructions': FORMAT_INSTRUCTIONS,\n","    #     'suffix': SUFFIX\n","    # }\n",")\n","\n","agent_executor.invoke({\"input\": \"Can you Explain in Detail The idea behind the paper CogVideo\"})"]}],"metadata":{"kernelspec":{"display_name":"venv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.4"}},"nbformat":4,"nbformat_minor":2}
